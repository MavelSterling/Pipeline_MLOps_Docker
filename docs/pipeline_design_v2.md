# Pipeline de MLOps para Diagn√≥stico M√©dico - Versi√≥n 2.0 (Taller #3)

## üéØ Descripci√≥n

Este documento describe el dise√±o **reestructurado y mejorado** de un pipeline de MLOps end-to-end para diagn√≥stico m√©dico, incorporando tecnolog√≠as modernas de MLOps, orquestaci√≥n, monitoreo y despliegue escalable en la nube.

**Problema a resolver:**
Construir un modelo que prediga, dados los s√≠ntomas de un paciente, si sufre de alguna enfermedad (com√∫n o hu√©rfana), con un pipeline completo que soporte:

- Despliegue local (para m√©dicos con recursos limitados)
- Despliegue en la nube (para acceso distribuido)
- Manejo de enfermedades comunes (muchos datos) y hu√©rfanas (pocos datos)
- Cumplimiento normativo (HIPAA, GDPR)

---

## üìä Diagrama del Pipeline MLOps End-to-End

```mermaid
graph TB
    subgraph "1. INGESTA Y ALMACENAMIENTO DE DATOS"
        A1[Azure Data Factory] --> A2[Azure Data Lake Gen2]
        A3[Fuentes: EHR/HL7/FHIR] --> A1
        A4[APIs de Hospitales] --> A1
        A2 --> A5[Delta Lake en Databricks]
    end

    subgraph "2. PROCESAMIENTO Y FEATURE ENGINEERING"
        A5 --> B1[Databricks Notebooks]
        B1 --> B2[Apache Spark para ETL]
        B2 --> B3[Feature Store - Databricks]
        B4[Great Expectations] -.validaci√≥n.-> B2
        B5[DVC - Version Control] -.versionado.-> A5
    end

    subgraph "3. ENTRENAMIENTO DE MODELOS"
        B3 --> C1[MLflow Experiments]
        C1 --> C2[Modelo: Enfermedades Comunes]
        C1 --> C3[Modelo: Enfermedades Hu√©rfanas]
        C1 --> C4[Few-Shot Learning]
      
        C2 --> C5[Ensemble Model]
        C3 --> C5
        C4 --> C3
      
        C5 --> C6[MLflow Model Registry]
      
        C7[Hyperparameter Tuning - Optuna] --> C1
        C8[AutoML - Databricks] -.opcional.-> C1
    end

    subgraph "4. VALIDACI√ìN Y TESTING"
        C6 --> D1[Testing Autom√°tico]
        D1 --> D2[Unit Tests - Pytest]
        D1 --> D3[Integration Tests]
        D1 --> D4[Model Validation]
        D4 --> D5[M√©tricas Cl√≠nicas]
        D5 --> D6[Validaci√≥n por Expertos]
    end

    subgraph "5. CI/CD PIPELINE"
        D6 --> E1[Azure DevOps / GitHub Actions]
        E1 --> E2[Build & Test]
        E2 --> E3[Containerizaci√≥n - Docker]
        E3 --> E4[Azure Container Registry]
        E4 --> E5[Deploy a Staging]
        E5 --> E6[A/B Testing]
        E6 --> E7[Deploy a Producci√≥n]
    end

    subgraph "6. DESPLIEGUE EN PRODUCCI√ìN"
        E7 --> F1[Azure Kubernetes Service]
        E7 --> F2[Azure Machine Learning Endpoints]
      
        F1 --> F3[API REST - FastAPI]
        F2 --> F3
      
        F3 --> F4[Azure API Management]
        F4 --> F5[M√©dico - Aplicaci√≥n Web]
        F4 --> F6[M√©dico - App M√≥vil]
        F4 --> F7[Integraci√≥n con EHR]
      
        F8[Azure Functions] -.batch inference.-> F3
    end

    subgraph "7. MONITOREO Y OBSERVABILIDAD"
        F3 --> G1[Azure Monitor]
        F3 --> G2[Application Insights]
        G1 --> G3[Prometheus]
        G3 --> G4[Grafana Dashboards]
      
        G5[Evidently AI] -.data drift.-> G3
        G6[Seldon Alibi] -.explicabilidad.-> F3
      
        G4 --> G7[Alertas Autom√°ticas]
    end

    subgraph "8. REENTRENAMIENTO Y MEJORA CONTINUA"
        G7 --> H1[Azure Logic Apps]
        H1 --> H2[Trigger Reentrenamiento]
        H2 --> H3[Databricks Jobs]
        H3 --> B1
      
        H4[Feedback de M√©dicos] --> H5[Azure Cosmos DB]
        H5 --> H2
    end

    subgraph "9. SEGURIDAD Y GOBERNANZA"
        I1[Azure Active Directory] --> F4
        I2[Azure Key Vault] --> F1
        I3[Azure Policy] -.compliance.-> A2
        I4[Audit Logs] --> G1
        I5[Encriptaci√≥n] --> A2
    end

    style A1 fill:#0078D4
    style A5 fill:#FF6C37
    style C1 fill:#0194E2
    style C6 fill:#0194E2
    style F1 fill:#326CE5
    style F3 fill:#009485
    style G4 fill:#F46800
```

---

## üèóÔ∏è ARQUITECTURA DETALLADA POR ETAPAS

### **ETAPA 1: Ingesta y Almacenamiento de Datos**

#### **Tecnolog√≠as:**

- **Azure Data Factory (ADF):** Orquestaci√≥n de pipelines de ingesta
- **Azure Data Lake Storage Gen2:** Almacenamiento escalable de datos crudos
- **Delta Lake (Databricks):** Formato de almacenamiento con ACID transactions
- **Apache Kafka (Azure Event Hubs):** Streaming de datos en tiempo real

#### **Justificaci√≥n:**

- **ADF** permite conectar m√∫ltiples fuentes heterog√©neas (EHR, laboratorios, APIs) sin c√≥digo
- **ADLS Gen2** ofrece almacenamiento econ√≥mico y escalable con particionado jer√°rquico
- **Delta Lake** proporciona versionado de datos, time travel y calidad transaccional
- **Event Hubs** permite ingesti√≥n en tiempo real de s√≠ntomas cr√≠ticos (urgencias)

#### **Suposiciones:**

- Los datos vienen en formatos est√°ndar de salud: HL7, FHIR, JSON
- Existen integraciones seguras con sistemas hospitalarios (VPN, API con OAuth2)
- Los datos hist√≥ricos est√°n disponibles para entrenamiento inicial (>10,000 registros)

#### **Flujo de datos:**

1. ADF se conecta a fuentes de datos cada hora (batch) o en tiempo real (streaming)
2. Datos crudos se escriben en ADLS Gen2 en formato parquet particionado por fecha
3. Databricks lee desde ADLS y carga en Delta Lake con schema enforcement
4. Se mantienen 3 capas: Bronze (raw), Silver (cleaned), Gold (features)

#### **Consideraciones de privacidad:**

- Encriptaci√≥n en tr√°nsito (TLS 1.3) y reposo (AES-256)
- Anonimizaci√≥n de datos personales usando Azure Purview
- Cumplimiento con HIPAA mediante Azure Compliance Manager

---

### **ETAPA 2: Procesamiento y Feature Engineering**

#### **Tecnolog√≠as:**

- **Databricks Notebooks + Apache Spark:** Procesamiento distribuido
- **Feature Store (Databricks):** Gesti√≥n centralizada de features
- **Great Expectations:** Validaci√≥n de calidad de datos
- **DVC (Data Version Control):** Versionado de datasets
- **PySpark + Pandas UDFs:** Transformaciones personalizadas

#### **Justificaci√≥n:**

- **Spark** escala horizontalmente para procesar millones de registros hist√≥ricos
- **Feature Store** evita duplicaci√≥n y asegura consistencia entre entrenamiento e inferencia
- **Great Expectations** valida autom√°ticamente esquemas, rangos y distribuciones
- **DVC** trackea versiones de datasets y permite reproducibilidad

#### **Procesamiento de s√≠ntomas:**

```python
# Ejemplo de feature engineering
- Normalizaci√≥n de escalas de dolor (0-10 estandarizado)
- Encoding de s√≠ntomas categ√≥ricos (one-hot, target encoding)
- Agregaciones temporales (s√≠ntomas √∫ltimas 24h, 7 d√≠as)
- Interacciones entre s√≠ntomas cr√≠ticos (fiebre + dolor_pecho)
- Embeddings de texto (descripciones en lenguaje natural con BioBERT)
- Imputaci√≥n de valores faltantes (KNN, MICE)
```

#### **Feature Store:**

- **Features para enfermedades comunes:** 150+ features de s√≠ntomas, demographics, historial
- **Features para enfermedades hu√©rfanas:** 50+ features clave + embeddings de casos similares
- **Actualizaci√≥n:** Online (streaming) y Offline (batch)
- **Serving:** API de baja latencia (<50ms) para inferencia

#### **Validaci√≥n de datos:**

```yaml
# Great Expectations suite
expectations:
  - expect_column_values_to_be_between:
      column: temperatura
      min: 35.0
      max: 42.0
  - expect_column_values_to_not_be_null:
      column: sintoma_principal
  - expect_table_row_count_to_be_between:
      min: 100
```

---

### **ETAPA 3: Entrenamiento de Modelos**

#### **Tecnolog√≠as:**

- **MLflow (Databricks):** Tracking, registro y gesti√≥n de modelos
- **Azure Machine Learning:** Plataforma alternativa/complementaria
- **Optuna / Hyperopt:** Hyperparameter tuning autom√°tico
- **AutoML (Databricks):** Exploraci√≥n r√°pida de modelos base
- **Frameworks:** Scikit-learn, XGBoost, LightGBM, PyTorch

#### **Estrategia de modelado:**

##### **Modelo 1: Enfermedades Comunes (muchos datos)**

- **Algoritmos:** XGBoost, LightGBM, Random Forest Ensemble
- **Datos:** >10,000 casos por condici√≥n
- **Entrenamiento:** Databricks cluster con GPUs (Standard_NC6s_v3)
- **M√©tricas:** Accuracy, F1-score, AUC-ROC
- **Validaci√≥n:** 5-fold cross-validation estratificada

##### **Modelo 2: Enfermedades Hu√©rfanas (pocos datos)**

- **Estrategia:** Few-shot learning + Transfer learning
- **Base model:** Modelo preentrenado en datos m√©dicos generales
- **Fine-tuning:** <100 ejemplos por condici√≥n rara
- **T√©cnicas:** Data augmentation, SMOTE, Siamese Networks
- **Prioridad:** Alta sensibilidad (recall) para no perder casos cr√≠ticos

##### **Modelo 3: Ensemble Final**

- **Arquitectura:** Stacking con meta-learner
- **L√≥gica de agregaci√≥n:**
  - Si Modelo 2 predice enfermedad hu√©rfana con confianza >0.7 ‚Üí alarma
  - Si Modelo 1 + Modelo 2 coinciden en severidad ‚Üí salida directa
  - Si hay discrepancia ‚Üí escalar al caso m√°s grave (principio de precauci√≥n cl√≠nica)

#### **MLflow Tracking:**

```python
import mlflow
with mlflow.start_run(run_name="ensemble_v2.3"):
    mlflow.log_params({
        "n_estimators": 500,
        "max_depth": 10,
        "learning_rate": 0.05
    })
    mlflow.log_metrics({
        "train_f1": 0.92,
        "val_f1": 0.88,
        "sensibilidad_casos_criticos": 0.95
    })
    mlflow.sklearn.log_model(model, "model")
    mlflow.log_artifact("confusion_matrix.png")
```

#### **Hyperparameter Tuning:**

- **Optuna** con Bayesian optimization
- **B√∫squeda distribuida** en Databricks cluster
- **Early stopping** basado en validaci√≥n
- **Presupuesto:** 500 trials por experimento

#### **Model Registry:**

- **Staging:** Modelo reci√©n entrenado, en pruebas
- **Production:** Modelo activo sirviendo inferencias
- **Archived:** Modelos antiguos para auditor√≠a
- **Transiciones:** Requieren aprobaci√≥n manual + validaci√≥n cl√≠nica

---

### **ETAPA 4: Validaci√≥n y Testing**

#### **Tecnolog√≠as:**

- **Pytest:** Unit tests y integration tests
- **Great Expectations:** Data validation
- **Deepchecks:** Validaci√≥n espec√≠fica de ML
- **SHAP / LIME:** Explicabilidad de modelos

#### **Niveles de testing:**

##### **1. Unit Tests**

```python
def test_model_input_validation():
    """Valida que el modelo rechace inputs inv√°lidos"""
    assert model.predict({"fiebre": -5}) raises ValueError

def test_model_output_range():
    """Valida que las predicciones est√©n en rango esperado"""
    pred = model.predict(valid_input)
    assert pred["severidad"] in [0, 1, 2, 3, 4]
```

##### **2. Integration Tests**

- Test de pipeline completo (ingesta ‚Üí predicci√≥n)
- Test de latencia (<500ms p99)
- Test de throughput (>100 requests/segundo)

##### **3. Model Validation**

- **M√©tricas cl√≠nicas espec√≠ficas:**
  - Sensibilidad casos urgentes: >95%
  - Especificidad casos leves: >80%
  - NPV (Negative Predictive Value): >98%
- **An√°lisis de subgrupos:**
  - Por edad (pediatr√≠a, adultos, geriatr√≠a)
  - Por g√©nero
  - Por tipo de enfermedad
- **Fairness metrics:**
  - Disparate impact <1.2
  - Equal opportunity difference <0.05

##### **4. Explicabilidad**

- **SHAP values** para cada predicci√≥n individual
- Dashboard de feature importance
- Ejemplos contrafactuales ("Si la fiebre fuera 38¬∞C en vez de 40¬∞C...")

##### **5. Validaci√≥n por Expertos M√©dicos**

- **Panel de 5+ m√©dicos** revisan 100 casos aleatorios
- **Checklist de validaci√≥n:**
  - ¬øLa predicci√≥n es cl√≠nicamente razonable?
  - ¬øLa explicaci√≥n es interpretable?
  - ¬øFalta informaci√≥n cr√≠tica?
  - ¬øEl nivel de severidad es apropiado?
- **Criterio de aprobaci√≥n:** >90% de acuerdo m√©dico

---

### **ETAPA 5: CI/CD Pipeline**

#### **Tecnolog√≠as:**

- **Azure DevOps Pipelines / GitHub Actions:** Orquestaci√≥n CI/CD
- **Docker:** Containerizaci√≥n reproducible
- **Azure Container Registry (ACR):** Registro privado de im√°genes
- **Terraform / ARM Templates:** Infrastructure as Code
- **pytest + coverage:** Testing automatizado

#### **Pipeline CI/CD:**

```yaml
# azure-pipelines.yml (ejemplo simplificado)
trigger:
  branches:
    - main
    - develop

stages:
  - stage: Build
    jobs:
      - job: BuildTest
        steps:
          - task: UsePythonVersion@0
            inputs:
              versionSpec: '3.10'
          - script: |
              pip install -r requirements.txt
              pytest tests/ --cov=src --cov-report=xml
          - task: PublishCodeCoverageResults@1

  - stage: BuildDocker
    jobs:
      - job: Docker
        steps:
          - task: Docker@2
            inputs:
              command: 'buildAndPush'
              repository: 'medical-diagnosis-mlops'
              tags: |
                $(Build.BuildId)
                latest

  - stage: DeployStaging
    jobs:
      - job: DeployAKS
        steps:
          - task: Kubernetes@1
            inputs:
              command: 'apply'
              namespace: 'staging'
              manifests: 'k8s/deployment-staging.yaml'

  - stage: ABTesting
    jobs:
      - job: RunABTest
        steps:
          - script: python scripts/ab_test.py --duration=24h

  - stage: DeployProduction
    condition: succeeded()
    jobs:
      - job: DeployProd
        steps:
          - task: Kubernetes@1
            inputs:
              command: 'apply'
              namespace: 'production'
              manifests: 'k8s/deployment-prod.yaml'
```

#### **Containerizaci√≥n:**

```dockerfile
# Dockerfile optimizado para producci√≥n
FROM python:3.10-slim

# Instalar dependencias del sistema
RUN apt-get update && apt-get install -y --no-install-recommends \
    gcc \
    && rm -rf /var/lib/apt/lists/*

# Crear usuario no-root
RUN useradd -m -u 1000 mlops
USER mlops

WORKDIR /app

# Copiar requirements y instalar
COPY --chown=mlops:mlops requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copiar c√≥digo y modelo
COPY --chown=mlops:mlops src/ ./src/
COPY --chown=mlops:mlops models/ ./models/

# Health check
HEALTHCHECK --interval=30s --timeout=10s --retries=3 \
  CMD curl -f http://localhost:8000/health || exit 1

# Exponer puerto
EXPOSE 8000

# Comando de inicio
CMD ["uvicorn", "src.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### **Estrategias de despliegue:**

- **Blue-Green Deployment:** Dos entornos id√©nticos, switch instant√°neo
- **Canary Release:** 5% ‚Üí 25% ‚Üí 50% ‚Üí 100% del tr√°fico gradualmente
- **A/B Testing:** Comparar modelo nuevo vs antiguo con m√©tricas de negocio

---

### **ETAPA 6: Despliegue en Producci√≥n**

#### **Tecnolog√≠as:**

- **Azure Kubernetes Service (AKS):** Orquestaci√≥n de contenedores
- **Azure Machine Learning Endpoints:** Endpoints gestionados (alternativa)
- **FastAPI:** Framework para API REST de alto rendimiento
- **Azure API Management:** Gateway centralizado con pol√≠ticas
- **Azure Functions:** Inferencia batch as√≠ncrona
- **NGINX Ingress Controller:** Load balancing y TLS termination

#### **Arquitectura de despliegue:**

##### **Opci√≥n 1: Despliegue en AKS (Recomendado)**

```yaml
# k8s/deployment-prod.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: medical-diagnosis-api
  namespace: production
spec:
  replicas: 3
  selector:
    matchLabels:
      app: medical-diagnosis
  template:
    metadata:
      labels:
        app: medical-diagnosis
        version: v2.0
    spec:
      containers:
      - name: api
        image: <ACR>.azurecr.io/medical-diagnosis:latest
        ports:
        - containerPort: 8000
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "2000m"
        env:
        - name: MODEL_PATH
          value: "/models/ensemble_v2"
        - name: AZURE_KEY_VAULT_URL
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: key-vault-url
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 10
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: medical-diagnosis-service
spec:
  type: LoadBalancer
  ports:
  - port: 80
    targetPort: 8000
  selector:
    app: medical-diagnosis
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: medical-diagnosis-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: medical-diagnosis-api
  minReplicas: 3
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

##### **Opci√≥n 2: Azure ML Managed Endpoints (Alternativa simplificada)**

- Para equipos peque√±os sin experiencia en Kubernetes
- Azure gestiona infraestructura, escalado, monitoreo
- M√°s costoso pero menos overhead operacional

#### **API REST con FastAPI:**

```python
# src/main.py
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field, validator
import mlflow
import numpy as np
from typing import Dict, List
import logging

app = FastAPI(title="Medical Diagnosis API", version="2.0")

# Cargar modelo al inicio
model = mlflow.pyfunc.load_model("models/ensemble_v2")
logger = logging.getLogger(__name__)

class SymptomsInput(BaseModel):
    """Schema de entrada de s√≠ntomas"""
    patient_id: str = Field(..., description="ID an√≥nimo del paciente")
    symptoms: Dict[str, float] = Field(
        ..., 
        description="Diccionario de s√≠ntomas y su intensidad (0-10)",
        example={
            "fiebre": 8.5,
            "dolor_pecho": 7.0,
            "dificultad_respirar": 6.5,
            "fatiga": 5.0
        }
    )
    age: int = Field(..., ge=0, le=120)
    gender: str = Field(..., regex="^(M|F|O)$")
    medical_history: List[str] = Field(default=[], description="Historial m√©dico")
  
    @validator('symptoms')
    def validate_symptoms(cls, v):
        """Valida que los s√≠ntomas est√©n en rango v√°lido"""
        for symptom, intensity in v.items():
            if not 0 <= intensity <= 10:
                raise ValueError(f"Intensidad de '{symptom}' debe estar entre 0 y 10")
        if len(v) < 3:
            raise ValueError("Se requieren al menos 3 s√≠ntomas")
        return v

class DiagnosisOutput(BaseModel):
    """Schema de salida del diagn√≥stico"""
    patient_id: str
    severity: str  # NO_ENFERMO, MOLESTIAS_LEVES, ENFERMEDAD_LEVE, ENFERMEDAD_AGUDA, ENFERMEDAD_CRONICA
    confidence: float
    top_conditions: List[Dict[str, float]]
    recommendations: List[str]
    requires_immediate_attention: bool
    explanation: Dict[str, float]  # SHAP values

@app.post("/predict", response_model=DiagnosisOutput)
async def predict_diagnosis(input_data: SymptomsInput):
    """
    Endpoint principal de predicci√≥n de diagn√≥stico.
  
    - **patient_id**: Identificador an√≥nimo del paciente
    - **symptoms**: Diccionario de s√≠ntomas con intensidad 0-10
    - **age**: Edad del paciente
    - **gender**: G√©nero (M/F/O)
    """
    try:
        # Preprocesar input
        features = preprocess_input(input_data)
      
        # Predicci√≥n
        prediction = model.predict(features)
      
        # Post-procesamiento
        output = postprocess_prediction(prediction, input_data.patient_id)
      
        # Log para auditor√≠a
        logger.info(f"Prediction for patient {input_data.patient_id}: {output.severity}")
      
        return output
      
    except Exception as e:
        logger.error(f"Error en predicci√≥n: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error en predicci√≥n: {str(e)}")

@app.get("/health")
async def health_check():
    """Health check para Kubernetes liveness probe"""
    return {"status": "healthy", "model_loaded": model is not None}

@app.get("/ready")
async def readiness_check():
    """Readiness check para Kubernetes readiness probe"""
    try:
        # Test r√°pido del modelo
        dummy_input = np.zeros((1, model.metadata.get_input_schema().shape[1]))
        _ = model.predict(dummy_input)
        return {"status": "ready"}
    except:
        raise HTTPException(status_code=503, detail="Model not ready")

@app.get("/metrics")
async def get_metrics():
    """Endpoint de m√©tricas para Prometheus"""
    # M√©tricas en formato Prometheus
    return {
        "predictions_total": 12500,
        "predictions_per_severity": {
            "NO_ENFERMO": 4500,
            "MOLESTIAS_LEVES": 3200,
            "ENFERMEDAD_LEVE": 2800,
            "ENFERMEDAD_AGUDA": 1500,
            "ENFERMEDAD_CRONICA": 500
        },
        "avg_latency_ms": 145,
        "p99_latency_ms": 380
    }

def preprocess_input(input_data: SymptomsInput) -> np.ndarray:
    """Preprocesa los datos de entrada para el modelo"""
    # Implementaci√≥n de feature engineering
    # (debe coincidir exactamente con el entrenamiento)
    pass

def postprocess_prediction(prediction, patient_id: str) -> DiagnosisOutput:
    """Post-procesa la salida del modelo"""
    # Implementaci√≥n de l√≥gica de negocio
    pass
```

#### **Azure API Management:**

- **Pol√≠ticas de seguridad:**
  - Autenticaci√≥n OAuth2 / API Keys
  - Rate limiting (100 requests/minuto por usuario)
  - IP whitelisting para hospitales
  - Validaci√≥n de JWT tokens
- **Transformaciones:**
  - Normalizaci√≥n de headers
  - Enriquecimiento de requests con metadata
- **Caching:**
  - Cache de diagn√≥sticos para mismos s√≠ntomas (1 hora)
- **Analytics:**
  - Dashboard de uso por hospital/m√©dico
  - Tiempos de respuesta por endpoint

#### **Inferencia Batch (Azure Functions):**

Para procesamiento nocturno de casos no urgentes:

```python
# function_app.py
import azure.functions as func
import mlflow

app = func.FunctionApp()

@app.function_name(name="BatchInference")
@app.schedule(schedule="0 0 2 * * *", arg_name="mytimer")  # 2 AM diario
def batch_inference(mytimer: func.TimerRequest) -> None:
    """Procesa casos no urgentes en batch"""
    # Leer casos pendientes de Cosmos DB
    # Ejecutar inferencia en batch
    # Guardar resultados
    pass
```

---

### **ETAPA 7: Monitoreo y Observabilidad**

#### **Tecnolog√≠as:**

- **Azure Monitor:** Monitoreo centralizado de infraestructura
- **Application Insights:** Telemetr√≠a de aplicaciones
- **Prometheus:** M√©tricas de tiempo real
- **Grafana:** Dashboards visuales
- **Evidently AI:** Detecci√≥n de data drift y model drift
- **Seldon Alibi:** Explicabilidad y detecci√≥n de outliers
- **Azure Log Analytics:** Logs centralizados
- **PagerDuty / Azure Alerts:** Sistema de alertas

#### **M√©tricas monitoreadas:**

##### **1. M√©tricas de Infraestructura**

- CPU, memoria, disco por pod
- Latencia de red
- Disponibilidad del servicio (SLA 99.9%)
- Throughput (requests/segundo)

##### **2. M√©tricas de Aplicaci√≥n**

```python
# M√©tricas custom con Prometheus client
from prometheus_client import Counter, Histogram, Gauge

# Contador de predicciones
predictions_total = Counter(
    'predictions_total', 
    'Total de predicciones realizadas',
    ['severity', 'model_version']
)

# Histograma de latencia
prediction_latency = Histogram(
    'prediction_latency_seconds',
    'Latencia de predicci√≥n en segundos',
    buckets=[0.05, 0.1, 0.2, 0.5, 1.0, 2.0]
)

# Gauge de confianza promedio
avg_confidence = Gauge(
    'avg_prediction_confidence',
    'Confianza promedio de predicciones √∫ltimas 1000'
)
```

##### **3. M√©tricas de ML**

```python
# Detecci√≥n de data drift con Evidently
from evidently.metric_preset import DataDriftPreset
from evidently.report import Report

report = Report(metrics=[
    DataDriftPreset()
])

report.run(
    reference_data=training_data,  # Datos de entrenamiento
    current_data=production_data   # Datos de producci√≥n √∫ltima semana
)

drift_metrics = report.as_dict()
# Alertar si drift > umbral
if drift_metrics['data_drift']['dataset_drift']:
    send_alert("Data drift detectado!")
```

**M√©tricas espec√≠ficas:**

- **Data Drift:** Comparaci√≥n de distribuciones de features (KS test, PSI)
- **Prediction Drift:** Cambio en distribuci√≥n de predicciones
- **Concept Drift:** Degradaci√≥n de m√©tricas (F1, Recall)
- **Feature Importance Drift:** Cambios en importancia de features

##### **4. M√©tricas Cl√≠nicas**

- Tasa de casos urgentes detectados vs perdidos (Daily)
- Tasa de falsos positivos (alarmas innecesarias)
- Tiempo promedio de respuesta API (target <500ms p99)
- Acuerdo con diagn√≥sticos posteriores (validaci√≥n retrospectiva)

#### **Dashboards de Grafana:**

**Dashboard 1: Operacional**

- Requests/segundo (l√≠nea de tiempo)
- Latencia p50, p95, p99 (√∫ltimas 24h)
- Tasa de errores 4xx, 5xx
- Pods activos y saludables
- CPU y memoria por pod

**Dashboard 2: ML Performance**

- Distribuci√≥n de severidades predichas (pie chart)
- Confianza promedio por hora (l√≠nea de tiempo)
- Data drift score (gauge)
- Top 10 features con mayor drift
- Comparaci√≥n modelo actual vs baseline

**Dashboard 3: Cl√≠nico**

- Casos urgentes detectados (contador)
- Tiempo respuesta para casos cr√≠ticos
- Feedback de m√©dicos (rating promedio)
- Casos que requieren revisi√≥n manual

#### **Sistema de Alertas:**

```yaml
# alertas.yaml (Prometheus AlertManager)
groups:
  - name: ml_model_alerts
    interval: 30s
    rules:
      - alert: HighErrorRate
        expr: rate(http_requests_total{status="500"}[5m]) > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Tasa de error alta en API"
          description: "{{ $value }} errores por segundo"

      - alert: DataDriftDetected
        expr: evidently_data_drift_score > 0.7
        for: 1h
        labels:
          severity: warning
        annotations:
          summary: "Data drift detectado"
          description: "Score de drift: {{ $value }}"

      - alert: HighLatency
        expr: histogram_quantile(0.99, prediction_latency_seconds) > 1.0
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Latencia p99 alta"
          description: "p99: {{ $value }}s"

      - alert: LowModelConfidence
        expr: avg_prediction_confidence < 0.6
        for: 30m
        labels:
          severity: warning
        annotations:
          summary: "Confianza del modelo baja"
          description: "Confianza promedio: {{ $value }}"
```

**Canales de notificaci√≥n:**

- **Critical:** PagerDuty ‚Üí Llamada telef√≥nica al equipo de guardia
- **Warning:** Microsoft Teams / Slack channel
- **Info:** Email al equipo de ML

#### **Explicabilidad en producci√≥n:**

```python
# Generar explicaciones SHAP en cada predicci√≥n
import shap

explainer = shap.TreeExplainer(model)

def explain_prediction(input_features):
    """Genera explicaci√≥n SHAP para una predicci√≥n"""
    shap_values = explainer.shap_values(input_features)
  
    explanation = {
        "top_positive_features": [
            {"feature": "fiebre", "impact": +2.3},
            {"feature": "dolor_pecho", "impact": +1.8},
        ],
        "top_negative_features": [
            {"feature": "edad_joven", "impact": -0.5}
        ],
        "base_value": 0.3,
        "final_value": 4.1  # Predicci√≥n final
    }
  
    return explanation
```

**Almacenamiento de explicaciones:**

- Guardar explicaciones en Azure Cosmos DB para auditor√≠a
- Disponibles para revisi√≥n m√©dica posterior
- Usadas en reportes de transparencia

---

### **ETAPA 8: Reentrenamiento y Mejora Continua**

#### **Tecnolog√≠as:**

- **Databricks Jobs:** Orquestaci√≥n de reentrenamiento automatizado
- **Azure Logic Apps:** Workflows automatizados
- **Azure Cosmos DB:** Almacenamiento de feedback m√©dico
- **MLflow:** Tracking de experimentos de reentrenamiento
- **Airflow (opcional):** Orquestaci√≥n compleja de pipelines

#### **Estrategia de reentrenamiento:**

##### **Triggers autom√°ticos:**

1. **Reentrenamiento programado:** Cada 2 semanas (m√≠nimo)
2. **Drift detectado:** Si data drift > 0.7 por >24h
3. **Degradaci√≥n de m√©tricas:** Si F1 cae >5% respecto baseline
4. **Acumulaci√≥n de feedback:** Cada 500 nuevos casos con feedback m√©dico

##### **Pipeline de reentrenamiento:**

```python
# databricks_job.py
from databricks import feature_store
import mlflow

def retraining_pipeline():
    """Pipeline completo de reentrenamiento"""
  
    # 1. Extraer nuevos datos
    new_data = extract_new_data(
        start_date=last_training_date,
        end_date=datetime.now()
    )
  
    # 2. Validar calidad de datos
    validation_report = validate_data_quality(new_data)
    if not validation_report.passed:
        raise Exception("Datos no pasan validaci√≥n")
  
    # 3. Combinar con datos hist√≥ricos
    training_data = combine_datasets(historical_data, new_data)
  
    # 4. Feature engineering
    features = feature_store.read_table("medical_features")
  
    # 5. Entrenar modelo nuevo
    with mlflow.start_run(run_name=f"retrain_{datetime.now()}"):
        new_model = train_model(training_data, features)
      
        # 6. Evaluar modelo nuevo
        new_metrics = evaluate_model(new_model, test_data)
      
        # 7. Comparar con modelo actual
        current_model = mlflow.pyfunc.load_model("models:/ensemble/Production")
        current_metrics = evaluate_model(current_model, test_data)
      
        # 8. Decidir si promover
        if new_metrics['f1'] > current_metrics['f1'] and \
           new_metrics['recall_critical'] >= current_metrics['recall_critical']:
          
            # Promover a Staging primero
            mlflow.register_model(
                model_uri=f"runs:/{mlflow.active_run().info.run_id}/model",
                name="ensemble",
                tags={"stage": "staging"}
            )
          
            # Notificar al equipo para revisi√≥n manual
            send_notification(
                f"Nuevo modelo en Staging. M√©tricas: {new_metrics}"
            )
        else:
            logging.info("Modelo nuevo no supera al actual, no se promueve")
  
    return new_model

# Ejecutar con Databricks Jobs (schedule: weekly)
```

##### **Validaci√≥n A/B en producci√≥n:**

```python
# Estrategia de canary release
def canary_deployment(new_model, current_model, duration_hours=24):
    """
    Despliega nuevo modelo con 10% de tr√°fico y compara m√©tricas.
    """
    # Configurar routing en API
    traffic_split = {
        "current_model": 0.9,
        "new_model": 0.1
    }
  
    # Recolectar m√©tricas por duration_hours
    metrics_current = collect_metrics(current_model, duration_hours)
    metrics_new = collect_metrics(new_model, duration_hours)
  
    # Comparar m√©tricas
    if is_new_model_better(metrics_new, metrics_current):
        # Incrementar tr√°fico gradualmente
        for split in [0.25, 0.5, 0.75, 1.0]:
            update_traffic_split({"new_model": split})
            wait(hours=4)
            if detect_issues():
                rollback()
                return False
      
        # Promover a Production
        promote_to_production(new_model)
        return True
    else:
        rollback()
        return False
```

#### **Feedback Loop:**

```python
# Sistema de feedback m√©dico
class FeedbackSystem:
    def collect_feedback(self, prediction_id: str, feedback: dict):
        """
        Recolecta feedback de m√©dicos sobre predicciones.
      
        feedback = {
            "prediction_id": "abc123",
            "actual_diagnosis": "ENFERMEDAD_AGUDA",
            "predicted_diagnosis": "ENFERMEDAD_LEVE",
            "was_correct": False,
            "doctor_notes": "S√≠ntomas de infarto at√≠pico",
            "timestamp": "2024-01-15T14:30:00Z"
        }
        """
        # Guardar en Cosmos DB
        feedback_db.insert(feedback)
      
        # Si hay discrepancia cr√≠tica, alertar
        if feedback['actual_diagnosis'] in ['ENFERMEDAD_AGUDA', 'ENFERMEDAD_CRONICA'] \
           and not feedback['was_correct']:
            alert_ml_team(f"Falso negativo cr√≠tico: {prediction_id}")
      
        # Si se acumulan 500 feedbacks, trigger retraining
        if feedback_db.count_since_last_training() >= 500:
            trigger_retraining_job()
```

#### **Monitoreo de modelo champion/challenger:**

- **Modelo Champion:** Modelo en producci√≥n actualmente
- **Modelo Challenger:** Nuevo modelo candidato
- **Shadow mode:** Challenger recibe mismas requests pero no afecta respuesta al usuario
- **Comparaci√≥n:** M√©tricas de ambos se comparan en tiempo real
- **Promoci√≥n:** Solo si challenger supera a champion de forma consistente por 7 d√≠as

---

### **ETAPA 9: Seguridad y Gobernanza**

#### **Tecnolog√≠as:**

- **Azure Active Directory (AAD):** Identidad y autenticaci√≥n
- **Azure Key Vault:** Gesti√≥n de secretos y certificados
- **Azure Policy:** Cumplimiento normativo
- **Azure Security Center:** Detecci√≥n de amenazas
- **Azure Purview:** Gobernanza de datos y linaje
- **Audit Logs:** Trazabilidad completa

#### **Controles de seguridad:**

##### **1. Autenticaci√≥n y Autorizaci√≥n**

```python
# Autenticaci√≥n con Azure AD
from fastapi import Depends, HTTPException, status
from fastapi.security import OAuth2PasswordBearer
from azure.identity import DefaultAzureCredential

oauth2_scheme = OAuth2PasswordBearer(tokenUrl="token")

async def verify_token(token: str = Depends(oauth2_scheme)):
    """Verifica token JWT de Azure AD"""
    try:
        credential = DefaultAzureCredential()
        # Validar token con AAD
        user_info = validate_aad_token(token)
      
        # Verificar permisos
        if "medical.diagnosis.read" not in user_info.permissions:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="Permisos insuficientes"
            )
      
        return user_info
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Token inv√°lido"
        )

# Endpoint protegido
@app.post("/predict")
async def predict(
    input_data: SymptomsInput,
    user: dict = Depends(verify_token)
):
    # Solo usuarios autenticados con permisos pueden acceder
    pass
```

**Roles y permisos:**

- **MedicoGeneral:** Puede hacer predicciones, ver explicaciones
- **MedicoAdmin:** + Acceso a m√©tricas agregadas, dashboard
- **DataScientist:** + Acceso a MLflow, experimentos, reentrenamiento
- **Auditor:** Solo lectura de logs y predicciones hist√≥ricas

##### **2. Gesti√≥n de Secretos**

```python
# Uso de Azure Key Vault
from azure.keyvault.secrets import SecretClient
from azure.identity import DefaultAzureCredential

credential = DefaultAzureCredential()
client = SecretClient(
    vault_url="https://myvault.vault.azure.net/",
    credential=credential
)

# Recuperar secretos de forma segura
db_connection_string = client.get_secret("CosmosDBConnectionString").value
api_key = client.get_secret("ExternalAPIKey").value

# NUNCA hardcodear secretos en c√≥digo
# NUNCA commitear secretos a Git
```

##### **3. Encriptaci√≥n**

- **En tr√°nsito:**

  - TLS 1.3 para todas las comunicaciones
  - Certificados SSL gestionados por Azure Key Vault
  - Mutual TLS (mTLS) entre microservicios
- **En reposo:**

  - Azure Storage Encryption (AES-256)
  - Encriptaci√≥n a nivel de columna para datos sensibles en Cosmos DB
  - Modelos ML encriptados en Azure Container Registry

##### **4. Auditor√≠a y Trazabilidad**

```python
# Logging completo de predicciones
import logging
import uuid
from datetime import datetime

class AuditLogger:
    def log_prediction(
        self, 
        user_id: str, 
        patient_id: str, 
        input_data: dict, 
        prediction: dict,
        model_version: str
    ):
        """Registra cada predicci√≥n para auditor√≠a"""
        audit_entry = {
            "event_id": str(uuid.uuid4()),
            "timestamp": datetime.utcnow().isoformat(),
            "event_type": "prediction",
            "user_id": user_id,
            "patient_id": patient_id,  # Anonimizado
            "input_hash": hash(str(input_data)),  # No guardar datos crudos
            "prediction": prediction,
            "model_version": model_version,
            "ip_address": get_client_ip(),
            "location": get_hospital_location(user_id)
        }
      
        # Guardar en Azure Log Analytics
        log_analytics_client.send(audit_entry)
      
        # Guardar en Cosmos DB para queries complejas
        cosmos_db.audit_logs.insert_one(audit_entry)
```

**Informaci√≥n auditada:**

- Qui√©n hizo la predicci√≥n (m√©dico, sistema)
- Cu√°ndo se hizo
- Qu√© datos se usaron (hash, no datos crudos por privacidad)
- Qu√© predijo el modelo
- Qu√© versi√≥n del modelo se us√≥
- Desde d√≥nde (hospital, IP)

##### **5. Cumplimiento Normativo**

**HIPAA (Health Insurance Portability and Accountability Act):**

- Encriptaci√≥n end-to-end
- Controles de acceso basados en roles
- Audit logs completos (retenci√≥n 7 a√±os)
- Business Associate Agreements (BAA) con Azure
- Disaster recovery y backups
- Procedimientos de breach notification

**GDPR (General Data Protection Regulation):**

- Derecho al olvido (eliminaci√≥n de datos personales)
- Portabilidad de datos
- Consentimiento expl√≠cito
- Minimizaci√≥n de datos (solo lo necesario)
- Anonimizaci√≥n/Pseudonimizaci√≥n
- Data Protection Impact Assessment (DPIA)

**FDA (Food and Drug Administration) - Si aplica como SaMD:**

- Validaci√≥n cl√≠nica documentada
- Control de versiones de software
- Trazabilidad de decisiones
- Procedimientos de gesti√≥n de riesgos
- Reporting de eventos adversos

##### **6. Privacidad y Anonimizaci√≥n**

```python
# Anonimizaci√≥n de datos antes de almacenar
import hashlib

def anonymize_patient_id(patient_id: str) -> str:
    """Hash irreversible de patient ID"""
    return hashlib.sha256(patient_id.encode()).hexdigest()

def remove_pii(data: dict) -> dict:
    """Elimina informaci√≥n personalmente identificable"""
    pii_fields = ['name', 'address', 'ssn', 'phone', 'email']
    return {k: v for k, v in data.items() if k not in pii_fields}

# Differential privacy en m√©tricas agregadas
from diffprivlib.mechanisms import Laplace

def get_aggregated_metrics(data):
    """M√©tricas agregadas con ruido diferencial"""
    epsilon = 0.1  # Budget de privacidad
    sensitivity = 1.0
  
    true_count = len(data)
    noisy_count = Laplace(epsilon=epsilon, sensitivity=sensitivity).randomise(true_count)
  
    return {"approximate_count": int(noisy_count)}
```

##### **7. Disaster Recovery y Business Continuity**

- **RPO (Recovery Point Objective):** 1 hora

  - Backups incrementales cada hora de Cosmos DB
  - Snapshots de modelos ML cada deployment
- **RTO (Recovery Time Objective):** 4 horas

  - Failover autom√°tico de AKS a regi√≥n secundaria
  - Modelos ML replicados en m√∫ltiples regiones
- **Estrategia de backup:**

  - Azure Site Recovery para infraestructura
  - Geo-replication de Cosmos DB (write: West US, read: East US, Europe West)
  - Versionado de modelos en MLflow (mantener √∫ltimas 10 versiones)

```yaml
# Estrategia multi-regi√≥n
regions:
  primary: West US 2
  secondary: East US 2
  
failover:
  automatic: true
  health_check_interval: 30s
  failover_threshold: 3_consecutive_failures
  
data_replication:
  cosmos_db: geo_redundant
  storage: RA-GRS  # Read-Access Geo-Redundant Storage
  container_registry: geo_replicated
```

---

## üîß TECNOLOG√çAS UTILIZADAS POR CATEGOR√çA

### **Data & Storage**

| Tecnolog√≠a                | Prop√≥sito           | Justificaci√≥n                                   |
| -------------------------- | -------------------- | ------------------------------------------------ |
| Azure Data Lake Gen2       | Data lake            | Almacenamiento escalable y econ√≥mico            |
| Delta Lake                 | Formato de datos     | ACID transactions, time travel, schema evolution |
| Azure Cosmos DB            | Base de datos NoSQL  | Baja latencia, geo-replication, multi-model      |
| Feature Store (Databricks) | Gesti√≥n de features | Consistencia entre training e inference          |

### **Processing & Computation**

| Tecnolog√≠a     | Prop√≥sito                | Justificaci√≥n                                 |
| --------------- | ------------------------- | ---------------------------------------------- |
| Databricks      | Plataforma unificada      | Spark, ML, colaboraci√≥n en un solo lugar      |
| Apache Spark    | Procesamiento distribuido | Escala para millones de registros              |
| Azure Functions | Serverless compute        | Inferencia batch sin gestionar infraestructura |

### **ML Lifecycle**

| Tecnolog√≠a           | Prop√≥sito                     | Justificaci√≥n                                  |
| --------------------- | ------------------------------ | ----------------------------------------------- |
| MLflow                | Experiment tracking & registry | Est√°ndar de facto, integraci√≥n con Databricks |
| Optuna                | Hyperparameter tuning          | Bayesian optimization eficiente                 |
| Scikit-learn, XGBoost | Algoritmos ML                  | Bibliotecas maduras y confiables                |
| PyTorch               | Deep learning                  | Flexibilidad para few-shot learning             |
| AutoML (Databricks)   | Baseline r√°pido               | Exploraci√≥n automatizada de modelos            |

### **Model Serving & APIs**

| Tecnolog√≠a              | Prop√≥sito                 | Justificaci√≥n                                     |
| ------------------------ | -------------------------- | -------------------------------------------------- |
| FastAPI                  | Framework web              | Alto rendimiento, validaci√≥n autom√°tica, OpenAPI |
| Azure Kubernetes Service | Orquestaci√≥n contenedores | Escalabilidad, resiliencia, est√°ndar industria    |
| Azure ML Endpoints       | Endpoints gestionados      | Alternativa simplificada a AKS                     |
| NGINX Ingress            | Load balancer              | Distribuci√≥n de carga, TLS termination            |
| Azure API Management     | API Gateway                | Seguridad, pol√≠ticas, analytics centralizado      |

### **CI/CD & IaC**

| Tecnolog√≠a                   | Prop√≥sito             | Justificaci√≥n                             |
| ----------------------------- | ---------------------- | ------------------------------------------ |
| Azure DevOps / GitHub Actions | CI/CD                  | Automatizaci√≥n de despliegues             |
| Docker                        | Containerizaci√≥n      | Reproducibilidad, portabilidad             |
| Terraform                     | Infrastructure as Code | Versionado de infraestructura, multi-cloud |
| Pytest                        | Testing                | Framework est√°ndar Python                 |

### **Monitoring & Observability**

| Tecnolog√≠a          | Prop√≥sito                | Justificaci√≥n                  |
| -------------------- | ------------------------- | ------------------------------- |
| Azure Monitor        | Monitoreo infraestructura | Integraci√≥n nativa con Azure   |
| Application Insights | APM                       | Telemetr√≠a de aplicaciones     |
| Prometheus           | M√©tricas                 | Est√°ndar de facto, flexible    |
| Grafana              | Visualizaci√≥n            | Dashboards personalizables      |
| Evidently AI         | Data/model drift          | Especializado en ML monitoring  |
| SHAP / LIME          | Explicabilidad            | Interpretaci√≥n de predicciones |

### **Security & Governance**

| Tecnolog√≠a            | Prop√≥sito           | Justificaci√≥n                    |
| ---------------------- | -------------------- | --------------------------------- |
| Azure Active Directory | Identidad            | SSO, MFA, gesti√≥n centralizada   |
| Azure Key Vault        | Gesti√≥n de secretos | Rotaci√≥n autom√°tica, auditor√≠a |
| Azure Policy           | Cumplimiento         | Enforcement de pol√≠ticas         |
| Azure Purview          | Gobernanza de datos  | Linaje, cat√°logo, clasificaci√≥n |

### **Orchestration**

| Tecnolog√≠a        | Prop√≥sito             | Justificaci√≥n                             |
| ------------------ | ---------------------- | ------------------------------------------ |
| Databricks Jobs    | Orquestaci√≥n ML       | Integraci√≥n nativa con Databricks         |
| Azure Logic Apps   | Workflows              | Low-code, integraci√≥n con servicios Azure |
| Airflow (opcional) | Orquestaci√≥n compleja | DAGs complejos si se requiere              |

---

## üöÄ MODOS DE DESPLIEGUE

### **Opci√≥n 1: Despliegue Local (M√©dico con recursos limitados)**

Para m√©dicos en √°reas rurales o sin conectividad confiable:

#### **Requisitos m√≠nimos:**

- Laptop/Desktop con Python 3.10+
- 8 GB RAM, 20 GB disco
- Sin conexi√≥n a internet requerida (despu√©s de instalaci√≥n inicial)

#### **Implementaci√≥n:**

```bash
# 1. Descargar modelo y dependencias (una sola vez con conexi√≥n)
mlflow models download --model-uri models:/ensemble/Production --dst ./local_model

# 2. Instalar aplicaci√≥n local
pip install medical-diagnosis-local

# 3. Ejecutar aplicaci√≥n de escritorio
medical-diagnosis-app --offline-mode
```

**Caracter√≠sticas:**

- Modelo ML embebido (100 MB aproximadamente)
- Interfaz gr√°fica simple (Electron o PyQt)
- Base de datos local SQLite para historial
- Sincronizaci√≥n opcional cuando hay conexi√≥n
- Actualizaciones de modelo via USB o conexi√≥n espor√°dica

**Limitaciones:**

- No actualizaci√≥n en tiempo real
- Sin acceso a historiales de otros m√©dicos
- Versi√≥n de modelo puede estar desfasada

---

### **Opci√≥n 2: Despliegue H√≠brido (Recomendado)**

M√©dico puede usar app local cuando no hay conexi√≥n, y API en nube cuando la hay:

```python
# Cliente inteligente con fallback
class HybridClient:
    def __init__(self):
        self.cloud_api = "https://api.medicaldiagnosis.com"
        self.local_model = load_local_model()
  
    def predict(self, symptoms):
        try:
            # Intentar con API en nube primero
            response = requests.post(
                f"{self.cloud_api}/predict",
                json=symptoms,
                timeout=2  # 2 segundos timeout
            )
            return response.json()
        except (requests.Timeout, requests.ConnectionError):
            # Fallback a modelo local
            logging.warning("Sin conexi√≥n, usando modelo local")
            return self.local_model.predict(symptoms)
```

---

### **Opci√≥n 3: Despliegue en Nube (Hospitales grandes)**

API REST en Azure accesible desde cualquier dispositivo:

```bash
# Endpoint p√∫blico
POST https://api.medicaldiagnosis.com/predict
Authorization: Bearer <JWT_TOKEN>
Content-Type: application/json

{
  "patient_id": "anon_12345",
  "symptoms": {
    "fiebre": 8.5,
    "dolor_pecho": 7.0,
    "dificultad_respirar": 6.5
  },
  "age": 45,
  "gender": "M"
}
```

**Respuesta:**

```json
{
  "patient_id": "anon_12345",
  "severity": "ENFERMEDAD_AGUDA",
  "confidence": 0.87,
  "top_conditions": [
    {"name": "Infarto agudo de miocardio", "probability": 0.65},
    {"name": "Neumon√≠a severa", "probability": 0.22}
  ],
  "requires_immediate_attention": true,
  "recommendations": [
    "Derivar a urgencias inmediatamente",
    "Solicitar ECG y troponinas",
    "Monitoreo continuo de signos vitales"
  ],
  "explanation": {
    "dolor_pecho": +2.1,
    "dificultad_respirar": +1.5,
    "edad_45": +0.3
  }
}
```

---

## üìà M√âTRICAS DE √âXITO DEL PIPELINE

### **M√©tricas T√©cnicas**

| M√©trica             | Target     | Actual |
| -------------------- | ---------- | ------ |
| Disponibilidad API   | 99.9%      | -      |
| Latencia p99         | <500ms     | -      |
| Throughput           | >100 req/s | -      |
| Data drift detectado | <7 d√≠as   | -      |
| Cobertura de tests   | >85%       | -      |

### **M√©tricas de ML**

| M√©trica                        | Target | Justificaci√≥n              |
| ------------------------------- | ------ | --------------------------- |
| F1-score (enfermedades comunes) | >0.85  | Balance precision/recall    |
| Recall (casos cr√≠ticos)        | >0.95  | No perder casos urgentes    |
| Precision (casos leves)         | >0.80  | Evitar alarmas innecesarias |
| NPV (Negative Predictive Value) | >0.98  | Confianza en "no enfermo"   |

### **M√©tricas de Negocio**

| M√©trica                            | Target   | Impacto                    |
| ----------------------------------- | -------- | -------------------------- |
| Tiempo de diagn√≥stico              | -30%     | Atenci√≥n m√°s r√°pida     |
| Satisfacci√≥n m√©dicos              | >4.0/5.0 | Adopci√≥n del sistema      |
| Casos cr√≠ticos detectados temprano | +25%     | Mejores outcomes cl√≠nicos |
| Falsos negativos cr√≠ticos          | <2%      | Seguridad del paciente     |

---

## üîÑ ESTRATEGIA DE DATOS PARA ENFERMEDADES HU√âRFANAS

**Desaf√≠o:** <100 casos hist√≥ricos por enfermedad rara.

**Soluciones implementadas:**

### **1. Transfer Learning**

- Pre-entrenar modelo en enfermedades comunes (100K+ casos)
- Fine-tuning con pocos ejemplos de enfermedades hu√©rfanas
- Aprovechar features compartidas (fiebre, dolor, etc.)

### **2. Few-Shot Learning**

- Siamese Networks: Aprender similitud entre casos
- Prototypical Networks: Clasificar basado en prototipos
- Matching Networks: Comparar con casos hist√≥ricos

### **3. Data Augmentation**

- SMOTE (Synthetic Minority Over-sampling)
- Variaciones sint√©ticas de s√≠ntomas (ruido controlado)
- Simulaciones cl√≠nicas basadas en literatura m√©dica

### **4. Meta-Learning**

- Model-Agnostic Meta-Learning (MAML)
- Aprender a aprender con pocos ejemplos
- Adaptaci√≥n r√°pida a nuevas enfermedades

### **5. Expert Knowledge**

- Reglas cl√≠nicas codificadas por m√©dicos especialistas
- S√≠ntomas patognom√≥nicos (√∫nicos de enfermedad)
- Combinaciones de s√≠ntomas de libros de medicina

### **6. Collaborative Learning**

- Federated learning con m√∫ltiples hospitales
- Compartir aprendizajes sin compartir datos crudos
- Agregar modelos entrenados en diferentes sitios

**Ejemplo de implementaci√≥n:**

```python
# Few-shot learning con Siamese Network
from tensorflow import keras

def create_siamese_network(input_shape):
    """Red siamesa para comparar casos similares"""
    # Base network (compartida)
    base_network = keras.Sequential([
        keras.layers.Dense(128, activation='relu'),
        keras.layers.Dropout(0.2),
        keras.layers.Dense(64, activation='relu'),
        keras.layers.Dense(32, activation='relu')
    ])
  
    # Dos inputs (caso actual + caso de referencia)
    input_a = keras.layers.Input(shape=input_shape)
    input_b = keras.layers.Input(shape=input_shape)
  
    # Procesar ambos con misma red
    processed_a = base_network(input_a)
    processed_b = base_network(input_b)
  
    # Distancia L1
    distance = keras.layers.Lambda(
        lambda tensors: K.abs(tensors[0] - tensors[1])
    )([processed_a, processed_b])
  
    # Salida: ¬øson similares?
    output = keras.layers.Dense(1, activation='sigmoid')(distance)
  
    model = keras.Model(inputs=[input_a, input_b], outputs=output)
  
    return model

# Entrenamiento
siamese_model = create_siamese_network(input_shape=(150,))
siamese_model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)

# En inferencia: comparar caso nuevo con casos hist√≥ricos de enfermedad hu√©rfana
def classify_rare_disease(new_case, historical_cases):
    similarities = []
    for hist_case in historical_cases:
        similarity = siamese_model.predict([new_case, hist_case])
        similarities.append({
            'case_id': hist_case.id,
            'disease': hist_case.disease,
            'similarity': similarity
        })
  
    # Clasificar por caso m√°s similar
    most_similar = max(similarities, key=lambda x: x['similarity'])
  
    if most_similar['similarity'] > 0.8:
        return most_similar['disease']
    else:
        return "CASO_ATIPICO_REQUIERE_REVISION"
```

---

## üéØSUPOSICIONES Y DECISIONES DE DISE√ëO

### **Suposiciones sobre Datos**

1. **Disponibilidad de datos hist√≥ricos:**

   - Suposici√≥n: Existen >10,000 casos hist√≥ricos de enfermedades comunes
   - Implicaci√≥n: Si hay menos, usar transfer learning de datasets p√∫blicos (MIMIC-III)
2. **Calidad de datos:**

   - Suposici√≥n: 70% de datos tienen labels verificados por m√©dicos
   - Implicaci√≥n: Implementar validaci√≥n humana en loop para mejorar calidad
3. **Formato de datos:**

   - Suposici√≥n: Datos vienen en est√°ndares HL7/FHIR
   - Implicaci√≥n: Si no, necesitar capa adicional de normalizaci√≥n
4. **Temporalidad:**

   - Suposici√≥n: S√≠ntomas son snapshot temporal, no series de tiempo
   - Implicaci√≥n: Si hay evoluci√≥n temporal, usar LSTM/RNNs

### **Suposiciones sobre Infraestructura**

1. **Budget:**

   - Suposici√≥n: Budget de ~$5,000-10,000/mes para infraestructura Azure
   - Implicaci√≥n: Si es menor, usar Azure ML Endpoints en vez de AKS
2. **Equipo:**

   - Suposici√≥n: Equipo de 2-3 ML engineers + 1 DevOps + m√©dicos consultores
   - Implicaci√≥n: Si equipo es m√°s peque√±o, usar m√°s servicios gestionados
3. **Tr√°fico:**

   - Suposici√≥n: ~10,000 predicciones/d√≠a (pico 100 req/s)
   - Implicaci√≥n: AKS con 3-5 pods es suficiente, escala a 20 si aumenta

### **Suposiciones sobre Regulaci√≥n**

1. **Clasificaci√≥n como SaMD:**

   - Suposici√≥n: El sistema se considera Software as a Medical Device (FDA Clase II)
   - Implicaci√≥n: Requiere validaci√≥n cl√≠nica formal y submission a FDA
2. **Cumplimiento HIPAA:**

   - Suposici√≥n: Se maneja Protected Health Information (PHI)
   - Implicaci√≥n: Azure debe estar configurado como HIPAA compliant
3. **Responsabilidad:**

   - Suposici√≥n: El sistema es de apoyo diagn√≥stico, decisi√≥n final es del m√©dico
   - Implicaci√≥n: UI debe dejar claro que es una herramienta de apoyo, no reemplazo

### **Decisiones de Dise√±o y Justificaci√≥n**

1. **¬øPor qu√© Azure + Databricks?**

   - **Pro:** Integraci√≥n nativa, Feature Store, MLflow integrado, colaboraci√≥n
   - **Pro:** Azure es l√≠der en healthcare cloud (HIPAA, HITRUST certified)
   - **Con:** Vendor lock-in (mitigado con MLflow y contenedores)
   - **Alternativas:** AWS SageMaker, GCP Vertex AI (igualmente v√°lidas)
2. **¬øPor qu√© Kubernetes en vez de Azure Functions?**

   - **Pro:** Mayor control, escalabilidad horizontal, monitoreo granular
   - **Pro:** Latencia m√°s predecible para casos cr√≠ticos
   - **Con:** M√°s complejo de mantener
   - **Decisi√≥n:** Usar AKS para API principal, Functions para batch
3. **¬øPor qu√© FastAPI en vez de Flask?**

   - **Pro:** Alto rendimiento (async), validaci√≥n autom√°tica, OpenAPI
   - **Pro:** Type hints nativos (mejor mantenibilidad)
   - **Con:** Menos ejemplos/recursos que Flask
   - **Decisi√≥n:** FastAPI es el est√°ndar moderno para ML APIs
4. **¬øPor qu√© ensemble en vez de un modelo √∫nico?**

   - **Pro:** Mejor manejo de casos raros con modelo especializado
   - **Pro:** Agregaci√≥n prioriza seguridad (falso negativo cr√≠tico es peor)
   - **Con:** Mayor complejidad de entrenamiento y despliegue
   - **Decisi√≥n:** Vale la pena para contexto m√©dico cr√≠tico
5. **¬øPor qu√© MLflow en vez de alternativas (Weights & Biases, Neptune)?**

   - **Pro:** Open source, integraci√≥n con Databricks, est√°ndar de facto
   - **Pro:** Model registry robusto, versionado, staging/production
   - **Con:** UI menos moderna que WandB
   - **Decisi√≥n:** MLflow es suficiente y evita vendor lock-in

---

## üîê CONSIDERACIONES √âTICAS

### **1. Bias y Fairness**

- **Riesgo:** Modelo puede tener bias contra ciertos grupos (g√©nero, etnia, edad)
- **Mitigaci√≥n:**
  - Auditar m√©tricas por subgrupo
  - Rebalancear dataset si hay subrepresentaci√≥n
  - Usar fairness constraints en entrenamiento (Fairlearn)
  - Revisi√≥n por comit√© de √©tica m√©dica

### **2. Explicabilidad**

- **Riesgo:** "Black box" no es aceptable en medicina
- **Mitigaci√≥n:**
  - SHAP values en cada predicci√≥n
  - Dashboard de feature importance
  - Ejemplos similares hist√≥ricos ("casos parecidos fueron...")

### **3. Responsabilidad**

- **Riesgo:** ¬øQui√©n es responsable si el modelo falla?
- **Decisi√≥n:**
  - Sistema es de "apoyo", no "reemplazo"
  - M√©dico tiene decisi√≥n final
  - Seguro de responsabilidad profesional cubre uso de herramientas

### **4. Privacidad**

- **Riesgo:** Filtraci√≥n de datos sensibles
- **Mitigaci√≥n:**
  - Anonimizaci√≥n estricta
  - Acceso basado en necesidad
  - Auditor√≠a completa
  - Derecho al olvido implementado

### **5. Acceso equitativo**

- **Riesgo:** Solo hospitales grandes pueden pagar sistema en nube
- **Mitigaci√≥n:**
  - Versi√≥n local gratuita para zonas rurales
  - Subsidios para hospitales p√∫blicos
  - Partnership con ONG de salud

---

## üìö REFERENCIAS Y RECURSOS

### **Papers de referencia:**

1. Esteva et al. (2021) - "Deep learning-enabled medical computer vision"
2. Rajkomar et al. (2019) - "Machine Learning in Medicine"
3. Futoma et al. (2020) - "The myth of generalizability in clinical research and machine learning in health care"

### **Frameworks y librer√≠as:**

- MLflow: https://mlflow.org/
- Databricks: https://databricks.com/
- FastAPI: https://fastapi.tiangolo.com/
- Evidently AI: https://evidentlyai.com/
- SHAP: https://shap.readthedocs.io/

### **Datasets p√∫blicos (para benchmark):**

- MIMIC-III: https://mimic.mit.edu/
- UK Biobank: https://www.ukbiobank.ac.uk/
- Synthetic datasets: https://synthea.mitre.org/

---

## ‚úÖ CONCLUSI√ìN

Este pipeline MLOps end-to-end cubre todas las etapas necesarias para llevar un modelo de diagn√≥stico m√©dico desde la idea hasta producci√≥n de forma segura, escalable y conforme a regulaciones.

**Ventajas clave del dise√±o:**

1. Escalable (de m√©dico local a hospital nacional)
2. Seguro (HIPAA, GDPR, encriptaci√≥n)
3. Robusto (monitoreo, alertas, reentrenamiento autom√°tico)
4. Explicable (SHAP, interpretabilidad)
5. Flexible (enfermedades comunes y hu√©rfanas)
6. Reproducible (IaC, contenedores, versionado)

---

*Proyecto desarrollado por Felipe Guerra y Mavelyn Sterling para el Taller #3 de MLOps - Maestr√≠a en Inteligencia Artificial Aplicada*

*Versi√≥n 2.0 - Pipeline MLOps End-to-End de Nivel Empresarial*
