# CHANGELOG - Pipeline de MLOps para Diagn√≥stico M√©dico

## üìã Registro de Cambios: Taller #1 ‚Üí Taller #3

Este documento detalla todos los cambios, mejoras y reestructuraciones realizadas entre la propuesta inicial (Taller #1) y la propuesta final (Taller #3).

---

## üéØ Resumen Ejecutivo de Cambios

| Aspecto                    | Taller #1 (Versi√≥n Inicial) | Taller #3 (Versi√≥n Mejorada)         |
| -------------------------- | ---------------------------- | ------------------------------------- |
| **Nivel de detalle** | Conceptual, general          | T√©cnico, espec√≠fico, implementable  |
| **Tecnolog√≠as**     | No especificadas             | 30+ tecnolog√≠as MLOps detalladas     |
| **Plataforma**       | Local con Docker             | Azure + Databricks + local            |
| **Orquestaci√≥n**    | No definida                  | Databricks Jobs + Azure DevOps        |
| **Monitoreo**        | Mencionado vagamente         | Prometheus + Grafana + Evidently AI   |
| **CI/CD**            | No presente                  | Pipeline completo Azure DevOps        |
| **Seguridad**        | Mencionada superficialmente  | Implementaci√≥n HIPAA + GDPR completa |
| **Explicabilidad**   | No definida                  | SHAP + LIME integrados                |
| **Escalabilidad**    | No especificada              | AKS con autoscaling 3-20 pods         |
| **Despliegue**       | Solo local                   | Local + H√≠brido + Nube               |

---

## üìä CAMBIOS POR ETAPA DEL PIPELINE

### **ETAPA 1: Ingesta y Almacenamiento de Datos**

#### ‚ùå **Versi√≥n Taller #1:**

```
- Descripci√≥n gen√©rica: "Ingesta de Datos"
- No especifica fuentes de datos
- No menciona formatos
- No define almacenamiento
- No considera streaming
```

#### ‚úÖ **Versi√≥n Taller #3:**

```
+ Azure Data Factory para orquestaci√≥n de ingesta
+ Azure Data Lake Storage Gen2 (almacenamiento escalable)
+ Delta Lake con ACID transactions y time travel
+ Azure Event Hubs para streaming en tiempo real
+ Soporte para HL7, FHIR, JSON
+ Arquitectura Bronze-Silver-Gold (medallion)
+ Particionado por fecha para optimizaci√≥n
+ Encriptaci√≥n AES-256 en reposo
+ Integraci√≥n segura con EHR via OAuth2
```

**Raz√≥n del cambio:**

- Necesidad de especificar tecnolog√≠as concretas y escalables
- Soporte para m√∫ltiples fuentes de datos heterog√©neas
- Cumplimiento con regulaciones de salud

---

### **ETAPA 2: Procesamiento y Feature Engineering**

#### ‚ùå **Versi√≥n Taller #1:**

```
- "Validaci√≥n y Limpieza" (sin detalles)
- "An√°lisis Exploratorio" (sin herramientas)
- No menciona Feature Store
- No especifica procesamiento distribuido
- No define validaci√≥n de calidad de datos
```

#### ‚úÖ **Versi√≥n Taller #3:**

```
+ Databricks Notebooks + Apache Spark (procesamiento distribuido)
+ Feature Store (Databricks) para consistencia train/inference
+ Great Expectations para validaci√≥n autom√°tica de calidad
+ DVC (Data Version Control) para versionado de datasets
+ PySpark + Pandas UDFs para transformaciones personalizadas
+ 150+ features para enfermedades comunes
+ 50+ features especializadas para enfermedades hu√©rfanas
+ Embeddings con BioBERT para texto m√©dico
+ Imputaci√≥n KNN/MICE para valores faltantes
+ SMOTE para balanceo de clases
```

**Raz√≥n del cambio:**

- Necesidad de procesar millones de registros (Spark)
- Evitar feature drift entre entrenamiento e inferencia (Feature Store)
- Garantizar calidad de datos con validaciones autom√°ticas
- Reproducibilidad con versionado de datos

---

### **ETAPA 3: Entrenamiento de Modelos**

#### ‚ùå **Versi√≥n Taller #1:**

```
- Menci√≥n gen√©rica de "Modelos Especializados"
- No especifica algoritmos
- No define estrategia para enfermedades hu√©rfanas
- No menciona experiment tracking
- No define hyperparameter tuning
- No especifica modelo ensemble
```

#### ‚úÖ **Versi√≥n Taller #3:**

```
+ MLflow para experiment tracking y model registry
+ Azure Machine Learning como alternativa/complementaria
+ Optuna/Hyperopt para hyperparameter tuning (500 trials)
+ AutoML (Databricks) para exploraci√≥n r√°pida
+ XGBoost, LightGBM, Random Forest para enfermedades comunes
+ Few-shot learning + Transfer learning para enfermedades hu√©rfanas
+ Siamese Networks para comparar casos similares
+ Meta-learning (MAML) para adaptaci√≥n r√°pida
+ Ensemble con meta-learner y l√≥gica de precauci√≥n cl√≠nica
+ Model Registry con estados: Staging ‚Üí Production ‚Üí Archived
+ Entrenamiento distribuido en GPU clusters (Standard_NC6s_v3)
+ Logging completo de par√°metros, m√©tricas y artefactos
```

**Raz√≥n del cambio:**

- Necesidad de tracking formal de experimentos (reproducibilidad)
- Estrategia espec√≠fica para pocos datos (enfermedades hu√©rfanas)
- Gesti√≥n profesional del ciclo de vida de modelos
- Optimizaci√≥n autom√°tica de hiperpar√°metros

---

### **ETAPA 4: Validaci√≥n y Testing**

#### ‚ùå **Versi√≥n Taller #1:**

```
- "Validaci√≥n Cruzada" (sin detalles)
- "Evaluaci√≥n de Modelos" (sin m√©tricas espec√≠ficas)
- Menci√≥n vaga de "validaci√≥n humana"
- No define tests automatizados
- No menciona explicabilidad
```

#### ‚úÖ **Versi√≥n Taller #3:**

```
+ Pytest para unit tests e integration tests
+ Great Expectations para data validation
+ Deepchecks para validaci√≥n espec√≠fica de ML
+ SHAP/LIME para explicabilidad
+ M√©tricas cl√≠nicas espec√≠ficas:
  - Sensibilidad casos urgentes: >95%
  - Especificidad casos leves: >80%
  - NPV (Negative Predictive Value): >98%
+ An√°lisis de fairness (disparate impact, equal opportunity)
+ Validaci√≥n por subgrupos (edad, g√©nero, tipo enfermedad)
+ Panel de 5+ m√©dicos especialistas (criterio >90% acuerdo)
+ Tests de latencia (<500ms p99)
+ Tests de throughput (>100 req/s)
+ Dashboard de feature importance
+ Ejemplos contrafactuales para interpretaci√≥n
```

**Raz√≥n del cambio:**

- Necesidad de testing automatizado completo
- Validaci√≥n no solo t√©cnica sino cl√≠nica
- Explicabilidad cr√≠tica en contexto m√©dico
- Detecci√≥n de bias y garant√≠a de fairness

---

### **ETAPA 5: CI/CD Pipeline**

#### ‚ùå **Versi√≥n Taller #1:**

```
- NO EXIST√çA en la propuesta original
- Solo hab√≠a Dockerfile manual
- No se mencionaba automatizaci√≥n
- No hab√≠a estrategia de despliegue
```

#### ‚úÖ **Versi√≥n Taller #3:**

```
+ Azure DevOps Pipelines / GitHub Actions completo
+ Pipeline de 5 etapas:
  1. Build & Test
  2. BuildDocker & Push to ACR
  3. Deploy to Staging
  4. A/B Testing (24h)
  5. Deploy to Production
+ Docker multi-stage builds optimizados
+ Azure Container Registry (ACR) privado
+ Terraform/ARM Templates para Infrastructure as Code
+ pytest + coverage autom√°tico (target >85%)
+ Blue-Green Deployment
+ Canary Release (5% ‚Üí 25% ‚Üí 50% ‚Üí 100%)
+ Rollback autom√°tico si detecta issues
+ Health checks y readiness probes
```

**Raz√≥n del cambio:**

- Automatizaci√≥n completa del despliegue (reduce errores humanos)
- Despliegues seguros con testing previo en staging
- Estrategias de despliegue sin downtime
- Rollback r√°pido en caso de problemas

---

### **ETAPA 6: Despliegue en Producci√≥n**

#### ‚ùå **Versi√≥n Taller #1:**

```
- Solo Flask + Docker local
- Sin estrategia de escalabilidad
- Sin load balancing
- Sin alta disponibilidad
- API no especificada
```

#### ‚úÖ **Versi√≥n Taller #3:**

```
+ Azure Kubernetes Service (AKS) con orquestaci√≥n completa
+ Azure ML Endpoints como alternativa simplificada
+ FastAPI (async, alto rendimiento, validaci√≥n autom√°tica)
+ NGINX Ingress Controller (load balancing, TLS)
+ Azure API Management (gateway centralizado)
+ Horizontal Pod Autoscaler (3-20 pods)
+ Configuraci√≥n de recursos (CPU, memoria) por pod
+ Liveness y Readiness probes
+ Multi-regi√≥n (West US 2 + East US 2)
+ Azure Functions para inferencia batch as√≠ncrona
+ Tres modos de despliegue:
  1. Local (offline, para zonas rurales)
  2. H√≠brido (cloud + local fallback)
  3. Nube completa (hospitales grandes)
+ API REST con validaci√≥n Pydantic
+ Endpoints: /predict, /health, /ready, /metrics
+ Geo-replication para disaster recovery
```

**Raz√≥n del cambio:**

- Necesidad de escalabilidad horizontal (muchos usuarios)
- Alta disponibilidad (99.9% SLA)
- M√∫ltiples opciones de despliegue seg√∫n contexto
- API profesional con validaci√≥n y documentaci√≥n autom√°tica

---

### **ETAPA 7: Monitoreo y Observabilidad**

#### ‚ùå **Versi√≥n Taller #1:**

```
- "Monitoreo en Tiempo Real" (sin herramientas)
- No especifica m√©tricas
- No define alertas
- No menciona data drift
- No especifica dashboards
```

#### ‚úÖ **Versi√≥n Taller #3:**

```
+ Azure Monitor (infraestructura)
+ Application Insights (telemetr√≠a de aplicaciones)
+ Prometheus (m√©tricas custom en tiempo real)
+ Grafana (3 dashboards: Operacional, ML Performance, Cl√≠nico)
+ Evidently AI (detecci√≥n autom√°tica de data drift)
+ Seldon Alibi (explicabilidad y outliers)
+ Azure Log Analytics (logs centralizados)
+ PagerDuty/Azure Alerts (sistema de alertas)
+ M√©tricas monitoreadas:
  - Infraestructura: CPU, memoria, latencia, throughput
  - Aplicaci√≥n: requests/s, errores 4xx/5xx, latencia p50/p95/p99
  - ML: data drift (KS test, PSI), prediction drift, concept drift
  - Cl√≠nicas: tasa detecci√≥n casos urgentes, falsos positivos, tiempo respuesta
+ Alertas con severidad (critical, warning, info)
+ Canales: PagerDuty (critical), Teams/Slack (warning), Email (info)
+ SHAP values en cada predicci√≥n para auditor√≠a
+ Almacenamiento de explicaciones en Cosmos DB
```

**Raz√≥n del cambio:**

- Monitoreo proactivo (detectar problemas antes de que afecten usuarios)
- Observabilidad completa (logs, m√©tricas, traces)
- Detecci√≥n temprana de degradaci√≥n del modelo
- Cumplimiento con requerimientos de auditor√≠a

---

### **ETAPA 8: Reentrenamiento y Mejora Continua**

#### ‚ùå **Versi√≥n Taller #1:**

```
- "Re-entrenamiento" (sin detalles)
- Flecha de retroalimentaci√≥n en diagrama
- No especifica triggers
- No define estrategia
- No menciona feedback loop
```

#### ‚úÖ **Versi√≥n Taller #3:**

```
+ Databricks Jobs para orquestaci√≥n de reentrenamiento
+ Azure Logic Apps para workflows automatizados
+ Azure Cosmos DB para almacenar feedback m√©dico
+ Triggers autom√°ticos:
  1. Programado (cada 2 semanas)
  2. Data drift >0.7 por >24h
  3. Degradaci√≥n m√©tricas (F1 cae >5%)
  4. Acumulaci√≥n de 500+ feedback de m√©dicos
+ Pipeline completo de reentrenamiento:
  1. Extraer nuevos datos
  2. Validar calidad (Great Expectations)
  3. Combinar con hist√≥ricos
  4. Feature engineering
  5. Entrenar modelo nuevo
  6. Evaluar y comparar con actual
  7. Promover a Staging si supera
  8. A/B testing en producci√≥n (24h-7 d√≠as)
  9. Promover a Production si exitoso
+ Estrategia Champion/Challenger (shadow mode)
+ Canary release gradual (10% ‚Üí 25% ‚Üí 50% ‚Üí 100%)
+ Rollback autom√°tico si issues
+ Sistema de feedback m√©dico:
  - Recolecci√≥n de diagn√≥sticos reales post-predicci√≥n
  - Alertas en caso de falsos negativos cr√≠ticos
  - An√°lisis de discrepancias
+ Versionado completo en MLflow
+ Auditor√≠a de cambios de modelo
```

**Raz√≥n del cambio:**

- Necesidad de adaptaci√≥n continua (concept drift es inevitable)
- Feedback loop formal con m√©dicos
- Reentrenamiento seguro (sin romper producci√≥n)
- Decisiones basadas en datos, no intuitivas

---

### **ETAPA 9: Seguridad y Gobernanza**

#### ‚ùå **Versi√≥n Taller #1:**

```
- Menci√≥n superficial de "privacidad"
- "Controles de acceso, trazabilidad"
- No especifica tecnolog√≠as
- No define cumplimiento normativo
- No menciona encriptaci√≥n
- No define auditor√≠a
```

#### ‚úÖ **Versi√≥n Taller #3:**

```
+ Azure Active Directory (SSO, MFA, RBAC)
+ Azure Key Vault (gesti√≥n de secretos con rotaci√≥n autom√°tica)
+ Azure Policy (enforcement de pol√≠ticas de compliance)
+ Azure Security Center (detecci√≥n de amenazas)
+ Azure Purview (gobernanza de datos, linaje)
+ Audit logs completos (retenci√≥n 7 a√±os)
+ Encriptaci√≥n:
  - En tr√°nsito: TLS 1.3, mTLS entre microservicios
  - En reposo: AES-256 en Storage, Cosmos DB, ACR
+ Roles definidos:
  - MedicoGeneral (predicciones, explicaciones)
  - MedicoAdmin (+ m√©tricas, dashboard)
  - DataScientist (+ MLflow, experimentos)
  - Auditor (solo lectura logs)
+ Cumplimiento normativo:
  - HIPAA compliant (BAA con Azure)
  - GDPR (derecho al olvido, portabilidad, minimizaci√≥n)
  - FDA (si aplica como SaMD): validaci√≥n cl√≠nica, trazabilidad
+ Auditor√≠a de predicciones:
  - Qui√©n: user_id del m√©dico
  - Cu√°ndo: timestamp UTC
  - Qu√©: hash de inputs (no datos crudos), predicci√≥n, modelo version
  - D√≥nde: hospital, IP
+ Anonimizaci√≥n:
  - SHA-256 hash de patient_id
  - Eliminaci√≥n de PII antes de almacenar
  - Differential privacy en m√©tricas agregadas
+ Disaster Recovery:
  - RPO: 1 hora (backups incrementales)
  - RTO: 4 horas (failover autom√°tico)
  - Geo-replication (West US, East US, Europe West)
+ Business Continuity:
  - Azure Site Recovery
  - Failover autom√°tico en <5 minutos
  - Versionado de modelos (√∫ltimas 10 versiones)
```

**Raz√≥n del cambio:**

- Cumplimiento obligatorio con HIPAA/GDPR/FDA
- Protecci√≥n de datos sensibles de salud
- Trazabilidad completa para auditor√≠as
- Gesti√≥n profesional de identidades y accesos

---

## üÜï COMPONENTES COMPLETAMENTE NUEVOS

### **1. Feature Store**

- **NO EXIST√çA** en Taller #1
- **Ahora:** Databricks Feature Store centralizado
- **Beneficio:** Consistencia entre training e inference, reutilizaci√≥n de features

### **2. Experiment Tracking**

- **NO EXIST√çA** en Taller #1
- **Ahora:** MLflow con tracking completo de experimentos
- **Beneficio:** Reproducibilidad, comparaci√≥n de modelos, auditor√≠a

### **3. Model Registry**

- **NO EXIST√çA** en Taller #1
- **Ahora:** MLflow Model Registry con Staging/Production
- **Beneficio:** Gesti√≥n formal del ciclo de vida de modelos

### **4. CI/CD Pipeline**

- **NO EXIST√çA** en Taller #1
- **Ahora:** Azure DevOps con 5 etapas automatizadas
- **Beneficio:** Despliegues seguros, r√°pidos y sin errores humanos

### **5. Data Drift Detection**

- **NO EXIST√çA** en Taller #1
- **Ahora:** Evidently AI con alertas autom√°ticas
- **Beneficio:** Detecci√≥n temprana de degradaci√≥n del modelo

### **6. Explicabilidad**

- **NO EXIST√çA** en Taller #1
- **Ahora:** SHAP/LIME en cada predicci√≥n
- **Beneficio:** Interpretabilidad para m√©dicos, cumplimiento regulatorio

### **7. API Management**

- **NO EXIST√çA** en Taller #1
- **Ahora:** Azure API Management con pol√≠ticas
- **Beneficio:** Seguridad centralizada, rate limiting, analytics

### **8. Orquestaci√≥n de Contenedores**

- **Taller #1:** Docker manual
- **Taller #3:** AKS con autoscaling, load balancing, multi-regi√≥n
- **Beneficio:** Escalabilidad autom√°tica, alta disponibilidad

### **9. Infrastructure as Code**

- **NO EXIST√çA** en Taller #1
- **Ahora:** Terraform/ARM Templates
- **Beneficio:** Reproducibilidad de infraestructura, versionado

### **10. Estrategia Few-Shot Learning**

- **Taller #1:** Mencionado vagamente
- **Taller #3:** Implementaci√≥n concreta con Siamese Networks, MAML
- **Beneficio:** Predicci√≥n efectiva con pocos datos (enfermedades hu√©rfanas)

---

## üîÑ CAMBIOS EN EL DIAGRAMA DEL PIPELINE

### **Taller #1:**

```
- Diagrama Mermaid simple con 14 nodos
- Flujo lineal con un loop de retroalimentaci√≥n
- Sin mencionar tecnolog√≠as espec√≠ficas
- Sin separaci√≥n clara de responsabilidades
- Sin incluir seguridad/gobernanza
```

### **Taller #3:**

```
+ Diagrama Mermaid completo con 50+ nodos
+ 9 subgrafos claramente separados:
  1. Ingesta y Almacenamiento
  2. Procesamiento y Feature Engineering
  3. Entrenamiento de Modelos
  4. Validaci√≥n y Testing
  5. CI/CD Pipeline
  6. Despliegue en Producci√≥n
  7. Monitoreo y Observabilidad
  8. Reentrenamiento y Mejora Continua
  9. Seguridad y Gobernanza
+ Cada nodo especifica tecnolog√≠a exacta
+ Conexiones expl√≠citas entre componentes
+ C√≥digo de colores para diferentes tecnolog√≠as
+ Incluye tanto flujos batch como streaming
+ Muestra m√∫ltiples opciones de despliegue
```

---

## üîÑCAMBIOS EN LA DOCUMENTACI√ìN

### **Taller #1:**

```
- README.md: 150 l√≠neas, b√°sico
- pipeline_design.md: 82 l√≠neas, conceptual
- Sin especificaciones t√©cnicas
- Sin justificaciones de decisiones
- Sin consideraciones de costos
- Sin m√©tricas de √©xito
```

### **Taller #3:**

```
+ pipeline_design_v2.md: 2000+ l√≠neas, extremadamente detallado
+ Cada etapa con:
  - Tecnolog√≠as espec√≠ficas con justificaci√≥n
  - C√≥digo de ejemplo funcional
  - Configuraciones YAML completas
  - Suposiciones expl√≠citas
  - Implicaciones de decisiones
+ Secciones nuevas:
  - Tabla comparativa de tecnolog√≠as
  - Estrategia para datos limitados
  - Modos de despliegue (local/h√≠brido/nube)
  - M√©tricas de √©xito (t√©cnicas, ML, negocio)
  - Consideraciones √©ticas (bias, fairness, privacidad)
  - Referencias y recursos
+ CHANGELOG.md completo (este documento)
+ README.md actualizado con referencias a v2
```

---

## üîÑCAMBIOS EN COSTOS ESTIMADOS

### **Taller #1:**

```
- No especificaba costos
- Solo mencionaba "computador local" o "servidor"
```

### **Taller #3:**

```
+ Estimaci√≥n mensual de infraestructura Azure:
  - Azure Data Lake Storage: ~$100/mes (1 TB)
  - Databricks (Standard): ~$2,000/mes (cluster intermitente)
  - AKS (3 nodes Standard_D4s_v3): ~$800/mes
  - Azure Cosmos DB: ~$500/mes (autoscale 4000-8000 RU/s)
  - Application Insights: ~$200/mes
  - Azure DevOps: ~$100/mes (5 usuarios)
  - Otros servicios (Key Vault, Monitor, etc.): ~$300/mes
  
  TOTAL: ~$4,000-5,000/mes (startup)
  Escalado: ~$8,000-10,000/mes (producci√≥n con alto tr√°fico)

+ Alternativa econ√≥mica (equipo peque√±o):
  - Azure ML Endpoints en vez de AKS: ~$1,500/mes
  - Databricks Community Edition: gratis (limitado)
  - TOTAL: ~$2,000-3,000/mes

+ Versi√≥n local: $0 (solo hardware del m√©dico)
```

---

## üîÑCAMBIOS EN SUPOSICIONES

### **Taller #1:**

```
- Pocas suposiciones expl√≠citas
- Vagamente mencionadas en el texto
- Sin implicaciones claras
```

### **Taller #3:**

```
+ Secci√≥n completa "Suposiciones y Decisiones de Dise√±o"
+ Suposiciones sobre datos:
  - Disponibilidad (>10,000 casos comunes, <100 raros)
  - Calidad (70% con labels verificados)
  - Formato (HL7, FHIR est√°ndar)
  - Temporalidad (snapshot vs series de tiempo)
+ Suposiciones sobre infraestructura:
  - Budget ($5K-10K/mes)
  - Equipo (2-3 ML engineers + 1 DevOps + m√©dicos)
  - Tr√°fico (~10K predicciones/d√≠a, pico 100 req/s)
+ Suposiciones sobre regulaci√≥n:
  - Clasificaci√≥n como SaMD (FDA Clase II)
  - Cumplimiento HIPAA obligatorio
  - Responsabilidad del m√©dico, no del sistema
+ Cada suposici√≥n con:
  - Implicaci√≥n si es cierta
  - Plan B si no se cumple
```

---

## üîÑCAMBIOS EN ESTRATEGIA DE MODELADO

### **Taller #1:**

```
- "Modelo para enfermedades comunes" (sin detalles)
- "Modelo para enfermedades hu√©rfanas" (sin detalles)
- "Modelo Ensemble" (sin especificar c√≥mo)
```

### **Taller #3:**

```
+ Modelo 1 - Enfermedades Comunes:
  - Algoritmos: XGBoost, LightGBM, Random Forest
  - Datos: >10,000 casos por condici√≥n
  - Entrenamiento: GPU cluster (Standard_NC6s_v3)
  - Validaci√≥n: 5-fold cross-validation estratificada
  - M√©tricas objetivo: Accuracy >85%, F1 >0.85

+ Modelo 2 - Enfermedades Hu√©rfanas:
  - Estrategia: Few-shot learning + Transfer learning
  - Base model: Preentrenado en datos m√©dicos generales
  - Fine-tuning: <100 ejemplos por condici√≥n
  - T√©cnicas: SMOTE, Siamese Networks, MAML
  - Prioridad: Alta sensibilidad (recall >95%)

+ Modelo 3 - Ensemble Final:
  - Arquitectura: Stacking con meta-learner
  - L√≥gica de agregaci√≥n: Priorizar riesgo cl√≠nico
  - Regla: "El peor caso manda" (principio de precauci√≥n)
  - C√≥digo completo de implementaci√≥n incluido

+ Hyperparameter Tuning:
  - Optuna con Bayesian optimization
  - 500 trials por experimento
  - B√∫squeda distribuida en Databricks
  - Early stopping en validaci√≥n

+ Transfer Learning:
  - Preentrenar en MIMIC-III (p√∫blico)
  - Fine-tuning en datos propios
  - Aprovechar features compartidas
```

---

## üõ°Ô∏è CAMBIOS EN SEGURIDAD

### **Taller #1:**

```
- Menci√≥n de "privacidad" y "controles de acceso"
- Sin implementaci√≥n concreta
- Sin cumplimiento normativo
```

### **Taller #3:**

```
+ Autenticaci√≥n:
  - Azure AD con SSO
  - OAuth2/JWT tokens
  - MFA obligatorio para accesos cr√≠ticos

+ Autorizaci√≥n:
  - RBAC con 4 roles definidos
  - Permisos granulares por endpoint
  - Principio de least privilege

+ Encriptaci√≥n:
  - TLS 1.3 en tr√°nsito
  - mTLS entre microservicios
  - AES-256 en reposo
  - Certificados en Key Vault

+ Secrets Management:
  - Azure Key Vault
  - Rotaci√≥n autom√°tica
  - NUNCA en c√≥digo/Git

+ Auditor√≠a:
  - Logs de cada predicci√≥n
  - Retenci√≥n 7 a√±os (HIPAA)
  - Trazabilidad completa (who, what, when, where)

+ Cumplimiento:
  - HIPAA (BAA con Azure)
  - GDPR (derecho al olvido implementado)
  - FDA si aplica (trazabilidad completa)

+ Disaster Recovery:
  - RPO 1h, RTO 4h
  - Geo-replication 3 regiones
  - Failover autom√°tico
```

---

## üìà CAMBIOS EN M√âTRICAS DE √âXITO

### **Taller #1:**

```
- No defin√≠a m√©tricas de √©xito
- Solo mencionaba "validaci√≥n cruzada" y "evaluaci√≥n"
```

### **Taller #3:**

```
+ M√©tricas T√©cnicas:
  - Disponibilidad API: 99.9% SLA
  - Latencia p99: <500ms
  - Throughput: >100 req/s
  - Data drift detectado: <7 d√≠as
  - Cobertura de tests: >85%

+ M√©tricas de ML:
  - F1-score (comunes): >0.85
  - Recall (cr√≠ticos): >0.95
  - Precision (leves): >0.80
  - NPV: >0.98

+ M√©tricas de Negocio:
  - Tiempo de diagn√≥stico: -30%
  - Satisfacci√≥n m√©dicos: >4.0/5.0
  - Casos cr√≠ticos detectados temprano: +25%
  - Falsos negativos cr√≠ticos: <2%

+ M√©tricas de Fairness:
  - Disparate impact: <1.2
  - Equal opportunity diff: <0.05
  - Performance por subgrupo (edad, g√©nero)
```

---

## üåç NUEVAS CAPACIDADES

| Capacidad                             | Taller #1     | Taller #3                          |
| ------------------------------------- | ------------- | ---------------------------------- |
| **Escalabilidad horizontal**    | ‚ùå No         | ‚úÖ AKS 3-20 pods autoscaling       |
| **Alta disponibilidad**         | ‚ùå No         | ‚úÖ Multi-regi√≥n con failover      |
| **Monitoreo en tiempo real**    | ‚ùå Mencionado | ‚úÖ Prometheus + Grafana completo   |
| **Explicabilidad**              | ‚ùå No         | ‚úÖ SHAP en cada predicci√≥n        |
| **Data drift detection**        | ‚ùå No         | ‚úÖ Evidently AI autom√°tico        |
| **Reentrenamiento autom√°tico** | ‚ùå No         | ‚úÖ Databricks Jobs con triggers    |
| **CI/CD**                       | ‚ùå No         | ‚úÖ Azure DevOps 5 etapas           |
| **A/B Testing**                 | ‚ùå No         | ‚úÖ Canary release gradual          |
| **Despliegue sin downtime**     | ‚ùå No         | ‚úÖ Blue-Green + Canary             |
| **Feature Store**               | ‚ùå No         | ‚úÖ Databricks Feature Store        |
| **Versioning de datos**         | ‚ùå No         | ‚úÖ DVC + Delta Lake                |
| **Versioning de modelos**       | ‚ùå No         | ‚úÖ MLflow Model Registry           |
| **Inferencia batch**            | ‚ùå No         | ‚úÖ Azure Functions                 |
| **Multi-modo despliegue**       | ‚ùå Solo local | ‚úÖ Local + H√≠brido + Nube         |
| **Cumplimiento HIPAA/GDPR**     | ‚ùå Mencionado | ‚úÖ Implementaci√≥n completa        |
| **Disaster Recovery**           | ‚ùå No         | ‚úÖ RPO 1h, RTO 4h, geo-replication |
| **API Documentation**           | ‚ùå No         | ‚úÖ OpenAPI autom√°tica (FastAPI)   |
| **Rate Limiting**               | ‚ùå No         | ‚úÖ Azure API Management            |
| **Caching**                     | ‚ùå No         | ‚úÖ Cache 1h para diagn√≥sticos     |
| **Feedback Loop**               | ‚ùå No         | ‚úÖ Sistema formal m√©dico feedback |

---

## üéØ CONCLUSI√ìN DE CAMBIOS

### **Impacto de los cambios:**

1. **De concepto a implementable:**

   - Taller #1 era una idea general
   - Taller #3 es un blueprint completo para implementar
2. **De local a enterprise:**

   - Taller #1 era solo Docker local
   - Taller #3 soporta desde m√©dico rural hasta hospital nacional
3. **De monol√≠tico a distribuido:**

   - Taller #1 era un servicio √∫nico
   - Taller #3 es arquitectura de microservicios escalable
4. **De reactivo a proactivo:**

   - Taller #1 no monitoreaba
   - Taller #3 detecta y alerta problemas antes de impacto
5. **De black-box a interpretable:**

   - Taller #1 no explicaba predicciones
   - Taller #3 provee SHAP values y justificaciones
6. **De inseguro a enterprise-grade:**

   - Taller #1 sin autenticaci√≥n/encriptaci√≥n
   - Taller #3 cumple HIPAA/GDPR/FDA
7. **De est√°tico a adaptativo:**

   - Taller #1 sin reentrenamiento
   - Taller #3 reentrenamiento autom√°tico con triggers

---

## üìö TECNOLOG√çAS AGREGADAS (30+)

**Taller #1:** Docker, Flask, Python b√°sico (3 tecnolog√≠as)

**Taller #3:**

1. Azure Data Factory
2. Azure Data Lake Gen2
3. Delta Lake
4. Azure Event Hubs
5. Databricks
6. Apache Spark
7. Feature Store (Databricks)
8. Great Expectations
9. DVC
10. MLflow
11. Optuna
12. Azure Machine Learning
13. Scikit-learn, XGBoost, LightGBM, PyTorch
14. AutoML
15. Pytest
16. Deepchecks
17. SHAP / LIME
18. Azure DevOps / GitHub Actions
19. Docker (optimizado)
20. Azure Container Registry
21. Terraform
22. FastAPI
23. Azure Kubernetes Service
24. NGINX Ingress
25. Azure API Management
26. Azure Functions
27. Azure Monitor
28. Application Insights
29. Prometheus
30. Grafana
31. Evidently AI
32. Seldon Alibi
33. Azure Active Directory
34. Azure Key Vault
35. Azure Policy
36. Azure Purview
37. Azure Cosmos DB
38. Azure Logic Apps

**Total: 38 tecnolog√≠as espec√≠ficas** (vs 3 en Taller #1)
-------------------------------------------------------

---

*Proyecto desarrollado por Felipe Guerra y Mavelyn Sterling para el Taller #3 de MLOps - Maestr√≠a en Inteligencia Artificial Aplicada*

*Versi√≥n 2.0 - Pipeline MLOps End-to-End de Nivel Empresarial*
